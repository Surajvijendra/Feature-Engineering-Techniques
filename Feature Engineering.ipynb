{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da802f6",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5576f6ff",
   "metadata": {},
   "source": [
    "It's is a process of Extract the features from the raw data using Domain Knowledge, then it's used in ML model to get better accurecy and predictions.\n",
    "\n",
    "* Feature Transformation\n",
    "* Feature Construction\n",
    "* Feature Selection\n",
    "* Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9544f",
   "metadata": {},
   "source": [
    "# 1. Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fef546",
   "metadata": {},
   "source": [
    "* Handeling Missing Values\n",
    "* Categorical encoding\n",
    "* Outlier Detection\n",
    "* Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945e028",
   "metadata": {},
   "source": [
    "### a. Handling Missing values\n",
    "\n",
    "**complete case analysis** by droping the missing values it leads to loosing some info so use when the missing values is less then 5%\n",
    "\n",
    "* for numerical data\n",
    "\n",
    "*fill it with mean or medien*\n",
    "\n",
    "**simpleImputer(strategy='mean')**\n",
    "\n",
    "* arbitary value imputation\n",
    "\n",
    "fill will the arbitary numbers like -1, 99, 0\n",
    "\n",
    "**categorycal data**\n",
    "\n",
    "* use the most reapeated values \n",
    "* fill with random values\n",
    "* Missing Indicators()\n",
    "* gridsearch cv()\n",
    "\n",
    "\n",
    "\n",
    "* KNN imputer\n",
    "* iterative method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580c96c",
   "metadata": {},
   "source": [
    "### b. Categorical Encoding\n",
    "1. Nominal encoding \n",
    "2. Ordinal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b803e",
   "metadata": {},
   "source": [
    "### 1. Nominal encoding(OneHotEncoder)\n",
    "\n",
    "It's used when there is no order in the data\n",
    "\n",
    "* pd.get_dummies(df, columns=['c'])\n",
    "\n",
    "###### from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e38454",
   "metadata": {},
   "source": [
    "### 2. Ordinal encoding\n",
    "\n",
    "it's used when there is order or priorities in the data \n",
    "\n",
    "###### from sklearn.preprocessing import OrdinalEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c185563",
   "metadata": {},
   "source": [
    "* Label Encoder\n",
    "\n",
    "it's used for target variables only\n",
    "\n",
    "###### from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42ca94",
   "metadata": {},
   "source": [
    "## C. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded8113",
   "metadata": {},
   "source": [
    "##### Handling outliers\n",
    "* Trimming method :- by removing the outliers.\n",
    "* capping method :- by giving the min or max values if it's out of range.\n",
    "* treat it as missing values or consider the ranges like 0-100, 20-30 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb6740",
   "metadata": {},
   "source": [
    "**Outliers Detection**\n",
    "\n",
    "1. Normal distibution\n",
    "2. Skewed distribution\n",
    "3. Percentail method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8f9b9",
   "metadata": {},
   "source": [
    "## d. feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d58ac",
   "metadata": {},
   "source": [
    "It's technique to standardize the independent feature in a fixed range.\n",
    "\n",
    "* Standardization(z-score Normalization)\n",
    "* Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0151e999",
   "metadata": {},
   "source": [
    "### 1. standardization(z-score) :\n",
    "\n",
    "It's a technique transforms the data to have a mean 0 and S.D 1.\n",
    "\n",
    "Formula:\n",
    "\n",
    "Xi' = (Xi - mean(Xi)) / (S.D)\n",
    "\n",
    "Xi --> independent feature \n",
    "\n",
    "S.D --> Standard deviatin\n",
    "\n",
    "mean Xi --> mean of independent meantures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39285d31",
   "metadata": {},
   "source": [
    "###### Library\n",
    "###### From sklearn.Preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05c1b6",
   "metadata": {},
   "source": [
    "### 2. Normalization\n",
    "\n",
    "It transforms the independent features in afixed range.\n",
    "\n",
    "* MinMax Scaler\n",
    "* MaxAbsolute Scaling\n",
    "* Robust Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc94e1",
   "metadata": {},
   "source": [
    "a. MinMax Scaling\n",
    "\n",
    "It transforms the data between 0 to 1\n",
    "\n",
    "formula\n",
    "\n",
    "Xi' = (Xi - Xi min) / (Xi max -Xi min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2c212c",
   "metadata": {},
   "source": [
    "###### From sklearn.Preprocessing import MixMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246494b5",
   "metadata": {},
   "source": [
    "b. MaxAbsolute Scaling\n",
    "\n",
    "formula\n",
    "\n",
    "Xi' = Xi / (|Xmax|)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d0e5e",
   "metadata": {},
   "source": [
    "c. Robust Scaling\n",
    "\n",
    "formula\n",
    "\n",
    "Xi' = (Xi - Xi medien) / IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6857ce",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ea69f",
   "metadata": {},
   "source": [
    "1. Function Trasformers\n",
    "it's used to transform the data as normal distribution\n",
    "* log use when there is a right skewed data\n",
    "* sqrt\n",
    "* reciprocal\n",
    "###### from sklearn.preprocessing import FunctionTrasnformers\n",
    "functiontransformers(func=np.log1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba37b9d",
   "metadata": {},
   "source": [
    "2. Power Transformers\n",
    "* Box-Cox\n",
    " \n",
    "is used when the lamda > 0\n",
    " \n",
    " \n",
    "* yeo-Johnson\n",
    "\n",
    "both +ve and -ve lamda values\n",
    "\n",
    "###### PowerTransformers(method=)\n",
    "\n",
    ".columns ,  PowerTransformers(method=).lamdas_        \n",
    "\n",
    "\n",
    "to get lamdas values of corresponding columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73429b4",
   "metadata": {},
   "source": [
    "### Column Transformer\n",
    "\n",
    "to do multiple transformer in a single stem use **columnTrasnformer**\n",
    "\n",
    "**from sklearn.compose import ColumnTransformer**\n",
    "\n",
    "trs = ColumnTransformer( transformer = [(),()], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fd3a2",
   "metadata": {},
   "source": [
    "## Handling datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a41fca",
   "metadata": {},
   "source": [
    "**import datetime**\n",
    "\n",
    "to convert to date time formate which saved as object use \n",
    "\n",
    "**pd.to_datetime(df['date column'])**\n",
    "\n",
    "* extract year\n",
    "\n",
    "**df['date column'].dt.year**\n",
    "\n",
    "* extract month\n",
    "\n",
    "**df['date column'].dt.month**\n",
    "\n",
    "* extract day\n",
    "\n",
    "**df['date column'].dt.day**\n",
    "\n",
    "* extract week\n",
    "\n",
    "**df['date column'].dt.week**\n",
    "\n",
    "* extract quarter\n",
    "\n",
    "**df['date column'].dt.quarter**\n",
    "\n",
    "* extract day in that week\n",
    "\n",
    "**df['date column'].dt.dayofweek**\n",
    "\n",
    "* extract date of that month\n",
    "\n",
    "**df['date column'].dt.day_name**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b68e3",
   "metadata": {},
   "source": [
    "to get today's date\n",
    "\n",
    "**datetime.datetime.today()**\n",
    "\n",
    "to get hours\n",
    "\n",
    "###### .dt.hour   dt.minutes  dt.second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba00b7",
   "metadata": {},
   "source": [
    "# 2. Feature construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3003df",
   "metadata": {},
   "source": [
    "**it have to be done based on the domain knowledge, by creating the new features from the data availables or features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6182e",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda326db",
   "metadata": {},
   "source": [
    "**using PCA(principle component analysis)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4b702",
   "metadata": {},
   "source": [
    "# 4. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863f7d9",
   "metadata": {},
   "source": [
    "**Based on the domain knowledge droping the unwanted features and retrieving the important features only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5509b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
